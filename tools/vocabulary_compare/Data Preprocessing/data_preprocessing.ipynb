{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Überblick über Daten\n",
    "\n",
    "- **ACDH-CH-Website** - https://www.oeaw.ac.at/acdh (Tags bei Projekten und Tools) - Englisch\n",
    "- **ARCHE** - https://arche.acdh.oeaw.ac.at (hasAppliedMethod, hasSubject, hasCategory) - Englisch/Deutsch\n",
    "- **DARIAH Campus** - https://campus.dariah.eu/ (Topics bei Resources) - Englisch\n",
    "- **dha Website** - https://digital-humanities.at/de/dha/projects (Tags bei Projekten) - Englisch/Deutsch\n",
    "- **dha Taxonomy** - https://vocabs.acdh.oeaw.ac.at/dha_taxonomy - Englisch\n",
    "- **GAMS** - https://gams.uni-graz.at/ (Tags/Keywords für Filter) - Englisch und Deutsch (Tags in Übersetzung vorhanden)\n",
    "- **HowTo des ACDH-CH** - https://howto.acdh.oeaw.ac.at (Tags bei Posts) - Englisch/Deutsch\n",
    "- **SSHOC** - sshoc-keyword.ttl from https://github.com/SSHOC/vocabularies/tree/main/SSHOpenMarketplace/sshoc-keyword - English\n",
    "- **TaDiRAH** - https://vocabs.dariah.eu/tadirah/en/ - Englisch\n",
    "- **TaDiRAH-Products** (modifizierte Variante, in Graz in Arbeit) - Englisch\n",
    "- **Zotero von KONDE** - https://www.zotero.org/groups/1332658/konde (manuelle und automatische Tags zu Sekundärliteratur) - Englisch/Deutsch/Französisch/Spanisch/Niederländisch etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import nltk\n",
    "from tabulate import tabulate\n",
    "from collections import Counter, defaultdict\n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from rdflib import Graph\n",
    "from rdfpandas.graph import to_dataframe\n",
    "import pandas as pd\n",
    "import rdflib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACDH-CH Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import der Tags der ACDH-CH-Website (acdh)\n",
    "#zusätzliche Informationen: Count für Tools, Count für Projekte, Count insgesamt\n",
    "\n",
    "acdh_orig = {}\n",
    "\n",
    "with open(\"Tags_ACDH-CH-Website.csv\", encoding = \"utf-8\") as datei:\n",
    "    for row in datei:\n",
    "        element = row.strip().split(\";\")\n",
    "        tag = element[0]\n",
    "        count_tools = element[1]\n",
    "        count_projects = element[2]\n",
    "        count = element[3]\n",
    "        if tag == \"\\ufeffTag\" or tag == \"Summe\":\n",
    "            continue\n",
    "        else:\n",
    "            acdh_orig[tag] = {\"count_tools\": count_tools, \"count_projects\": count_projects, \"count\": count}\n",
    "\n",
    "acdh = {key.lower():value for (key,value) in acdh_orig.items()}\n",
    "\n",
    "with open(\"acdhch_website.json\", \"w\", encoding = \"utf-8\") as datei:\n",
    "    json.dump(acdh, datei, ensure_ascii = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARCHE (hasAppliedMethod, hasSubject, hasCategory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler - unbekannte Kategorie: 1 (Zeile: 572)\n"
     ]
    }
   ],
   "source": [
    "#Import der ARCHE-Tags (hasSubject + hasAppliedMethod + hasCategory)\n",
    "#zusätzliche Informationen: Count, Property\n",
    "#Behandlung der drei Properties als drei verschiedene Vokabularien\n",
    "\n",
    "arche_hasSubject_orig = {}\n",
    "arche_hasAppliedMethod_orig = {}\n",
    "arche_hasCategory_orig = {}\n",
    "counter = 0\n",
    "\n",
    "with open(\"ARCHE_erweitert_2022-09-29.csv\", encoding = \"utf-8\") as datei:\n",
    "    for row in datei:\n",
    "        counter = counter + 1\n",
    "        element = row.replace(\"Ã¤\", \"ä\").replace(\"Ã¶\", \"ö\").replace(\"Ã¼\", \"ü\").replace(\"ÃŸ\", \"ß\").replace(\"Ã–\", \"Ö\").replace(\"Ã„\", \"Ä\").replace(\"Ãœ\", \"Ü\").replace(\"Ã¡\", \"á\").replace(\"ÄŸ\", \"ğ\").replace(\"Ã©\", \"é\").strip().split(\";\")\n",
    "        if element[0] == \"\\ufeffsubject\":\n",
    "            continue\n",
    "        else:\n",
    "            tag = element[0]\n",
    "            count = element[1]\n",
    "            if element[2] == \"hasSubject\":\n",
    "                arche_hasSubject_orig[tag] = count\n",
    "            elif element[2] == \"hasAppliedMethod\":\n",
    "                arche_hasAppliedMethod_orig[tag] = count\n",
    "            elif element[2] == \"hasCategory\":\n",
    "                arche_hasCategory_orig[tag] = count\n",
    "            else:\n",
    "                print(\"Fehler - unbekannte Kategorie: \" + element[2] + \" (Zeile: \" + str(counter) + \")\")\n",
    "\n",
    "#manuelle Aufnahme von einem Fall mit \";\" innerhalb von subject (s. Fehlermeldung im Output)\n",
    "arche_hasSubject_orig[\"25er-Ausschuss; Fünfundzwanziger-Ausschuss\"] = 1\n",
    "\n",
    "arche_hasAppliedMethod = {key.lower():value for (key,value) in arche_hasAppliedMethod_orig.items()}\n",
    "arche_hasCategory = {key.lower():value for (key,value) in arche_hasCategory_orig.items()}\n",
    "arche_hasSubject = {key.lower():value for (key,value) in arche_hasSubject_orig.items()}\n",
    "\n",
    "#manuelle Nachkorrektur des Counts bei Dopplungen (Hintergrund: erster Key wurde hier automatisch durch zweiten Key überschrieben)\n",
    "\n",
    "arche_hasSubject[\"military frontier\"] = 9\n",
    "arche_hasSubject[\"bibliography\"] = 9\n",
    "\n",
    "arche = {}\n",
    "for key in arche_hasAppliedMethod:\n",
    "    if key not in arche:\n",
    "        arche[key] = {}\n",
    "for key in arche_hasCategory:\n",
    "    if key not in arche:\n",
    "        arche[key] = {}\n",
    "for key in arche_hasSubject:\n",
    "    if key not in arche:\n",
    "        arche[key] = {}\n",
    "\n",
    "with open(\"arche.json\", \"w\", encoding = \"utf-8\") as datei:\n",
    "    json.dump(arche, datei, ensure_ascii = False)\n",
    "\n",
    "with open(\"arche_hasAppliedMethod.json\", \"w\", encoding = \"utf-8\") as datei:\n",
    "    json.dump(arche_hasAppliedMethod, datei, ensure_ascii = False)\n",
    "\n",
    "with open(\"arche_hasCategory.json\", \"w\", encoding = \"utf-8\") as datei:\n",
    "    json.dump(arche_hasCategory, datei, ensure_ascii = False)\n",
    "\n",
    "with open(\"arche_hasSubject.json\", \"w\", encoding = \"utf-8\") as datei:\n",
    "    json.dump(arche_hasSubject, datei, ensure_ascii = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DARIAH Campus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import von DARIAH-Campus (dc)\n",
    "#zusätzliche Informationen: Count\n",
    "\n",
    "with open(\"DARIAH-Campus_Topics.json\", encoding = \"utf-8\") as datei:\n",
    "    dc_orig = json.load(datei)\n",
    "\n",
    "dc = {key.lower():value for (key,value) in dc_orig.items()}\n",
    "\n",
    "with open(\"dariah_campus.json\", \"w\", encoding = \"utf-8\") as datei:\n",
    "    json.dump(dc, datei, ensure_ascii = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dha Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import der dha-Website-Tags\n",
    "#Notiz: eine Dopplung (\"political science\" zweimal, mit je Count = 1) direkt im .csv korrigiert\n",
    "\n",
    "dha_orig = {}\n",
    "\n",
    "with open(\"dha-tags-count_20220928.csv\", encoding = \"utf-8\") as datei:\n",
    "    for row in datei:\n",
    "        element = row.strip().split(\",\")\n",
    "        if element[0] == \"Name\":\n",
    "            continue\n",
    "        else: \n",
    "            tag = element[0]\n",
    "            count = element[1]\n",
    "            dha_orig[tag] = count\n",
    "\n",
    "#manuelle Korrektur eines Eintrags mit Beistrichen im Tag\n",
    "del dha_orig[\"Formats\"]\n",
    "dha_orig[\"Formats, Protocols, Standards\"] = 1\n",
    "\n",
    "dha = {key.lower():value for (key,value) in dha_orig.items()}\n",
    "\n",
    "with open(\"dha_website.json\", \"w\", encoding = \"utf-8\") as datei:\n",
    "    json.dump(dha, datei, ensure_ascii = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dha Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = rdflib.Graph()\n",
    "g.parse('dhataxonomy.ttl', format = 'ttl')\n",
    "df = to_dataframe(g)\n",
    "df.to_csv('dha_taxonomy.csv', sep=\"#\")\n",
    "\n",
    "keywords = {}\n",
    "\n",
    "with open(\"dha_taxonomy.csv\", encoding = \"utf-8\") as datei:\n",
    "    for row in datei:\n",
    "        liste = row.split(\"#\")\n",
    "        tag = liste[9].strip()\n",
    "        link = liste[0].strip()\n",
    "        creator = liste[1].strip()\n",
    "        definition = liste[6].strip()\n",
    "        tag_cleaned = tag.replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
    "        if tag != r\"skos:prefLabel{Literal}@en\" and tag != \"\":\n",
    "            keywords[tag_cleaned] = {\"link\": link, \"creator\": creator, \"definition\": definition}\n",
    "\n",
    "with open(\"dha_taxonomy.json\", \"w\", encoding = \"utf-8\") as datei:\n",
    "    json.dump(keywords, datei, ensure_ascii = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import der Tags von GAMS\n",
    "#zusätzliche Informationen: Sprache (de/en), Kategorie (Disziplin/Thema/Quellenmaterial/Methode/Periode), ID (selbst hinzugefügt, um Übersetzungen wiederzufinden)\n",
    "\n",
    "gams_orig = {}\n",
    "\n",
    "with open(\"GAMS.csv\", encoding = \"utf-8\") as datei:\n",
    "    for row in datei:\n",
    "        element = row.strip().split(\";\")\n",
    "        tag = element[0]\n",
    "        lang = element[1] #Sprache\n",
    "        cat = element[2] #Kategorie\n",
    "        id = element[3] #ID\n",
    "        if tag == \"\\ufeffTag\":\n",
    "            continue\n",
    "        else:\n",
    "            gams_orig[tag] = {\"lang\": lang, \"cat\": cat, \"id\": id}\n",
    "\n",
    "gams = {key.lower():value for (key,value) in gams_orig.items()}\n",
    "\n",
    "#manuelle Nachkorrektur des Counts bei Dopplungen (Hintergrund: erster Key wurde hier automatisch durch zweiten Key überschrieben)\n",
    "gams[\"numismatics\"][\"cat\"] = [\"Disziplin\", \"Thema\"]\n",
    "gams[\"numismatics\"][\"id\"] = [\"16\", \"30\"]\n",
    "\n",
    "with open(\"gams.json\", \"w\", encoding = \"utf-8\") as datei:\n",
    "    json.dump(gams, datei, ensure_ascii = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HowTo (ACDH-CH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import der manuell ergänzten Version der Tags des ACDH-CH HowTo (ht)\n",
    "#zusätzliche Informationen: Description, Count\n",
    "\n",
    "with open(\"HowTo_ergänzt.json\", encoding = \"utf-8\") as datei:\n",
    "    ht_orig = json.load(datei)\n",
    "\n",
    "ht = {key.lower():value for (key,value) in ht_orig.items()}\n",
    "\n",
    "with open(\"howto.json\", \"w\", encoding = \"utf-8\") as datei:\n",
    "    json.dump(ht, datei, ensure_ascii = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSHOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = rdflib.Graph()\n",
    "g.parse('sshoc-keyword.ttl', format = 'ttl')\n",
    "df = to_dataframe(g)\n",
    "df.to_csv('sshoc-keywords.csv', sep=\"#\")\n",
    "\n",
    "keywords = {}\n",
    "\n",
    "with open(\"sshoc-keywords.csv\", encoding = \"utf-8\") as datei:\n",
    "    for row in datei:\n",
    "        tag = row.split(\"#\")[6]\n",
    "        tag_cleaned = tag.replace(\"_\", \" \").replace(\"-\", \" \").replace(\"SSK:\", \"\").lower().strip()\n",
    "        if tag != r\"rdfs:label{Literal}@en\":\n",
    "            keywords[tag_cleaned] = {}\n",
    "\n",
    "with open(\"SSHOC.json\", \"w\", encoding = \"utf-8\") as datei:\n",
    "    json.dump(keywords, datei, ensure_ascii = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TaDiRAH Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import der TaDiRAH-Tags\n",
    "#zusätzliche Information: Synonym, falls es sich bei Tag um alternative Bezeichnung handelt (z.B. OCR --> Optical Character Recognition)\n",
    "\n",
    "tadirah_orig = {}\n",
    "\n",
    "with open(\"TaDiRAH.csv\", encoding = \"utf-8\") as datei:\n",
    "    for row in datei:\n",
    "        element = row.strip().split(\";\")\n",
    "        tag = element[0]\n",
    "        synonym = element[1] \n",
    "        if tag == \"\\ufeffTag\":\n",
    "            continue\n",
    "        else:\n",
    "            tadirah_orig[tag] = {\"synonym\": synonym}\n",
    "\n",
    "tadirah = {key.lower():value for (key,value) in tadirah_orig.items()}\n",
    "\n",
    "with open(\"tadirah_processes.json\", \"w\", encoding = \"utf-8\") as datei:\n",
    "    json.dump(tadirah, datei, ensure_ascii = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TaDiRAH Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import der TaDiRAH-Product-Tags\n",
    "#zusätzliche Information: Level in Tadirah, Synonym, gemappter Terminus in dha, gemappter Terminus in Wikidata\n",
    "\n",
    "tadirah_prod_orig = {}\n",
    "\n",
    "with open(\"TaDiRAH_products.csv\", encoding = \"utf-8\") as datei:\n",
    "    for row in datei:\n",
    "        element = row.strip().split(\";\")\n",
    "        tag = element[1].strip(\"()?\") #aktuell noch Klammern und Fragezeichen im GoogleSheet - hier herausgelöscht\n",
    "        level = element[2] #Level in Tadirah (wenn ein Tag auf mehreren Leveln vorkommt, werden diese in einer Liste gesammelt)\n",
    "        synonym = element[3] #etwaige eingetragene Synonyme - z.B. Addition zu Adding\n",
    "        dha_match = element[4] #gemappter Terminus im dha-Tagset\n",
    "        #hier noch wiki-data-match einfügen (sobald in csv übertragen)\n",
    "        if tag == \"Tag\" or tag == \"\":\n",
    "            continue\n",
    "        else:\n",
    "            if tag not in tadirah_prod_orig.keys():\n",
    "                tadirah_prod_orig[tag] = {\"level\": [level], \"synonym\": synonym, \"dha_match\": dha_match}\n",
    "            else:\n",
    "                tadirah_prod_orig[tag][\"level\"].append(level)\n",
    "\n",
    "tadirah_prod = {key.lower():value for (key,value) in tadirah_prod_orig.items()}\n",
    "\n",
    "with open(\"tadirah_products.json\", \"w\", encoding = \"utf-8\") as datei:\n",
    "    json.dump(tadirah_prod, datei, ensure_ascii = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zotero (KONDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import der Tags von KONDE-Zotero-Gruppe\n",
    "#Zusatzinformation: Sprache (manuell jweils als en, de, en/de oder other (d.h. andere Sprache) klassifiziert)\n",
    "\n",
    "zotero_orig = {}\n",
    "\n",
    "##Extraschritt bei Zotero: Cleaning von metatextuellen Markierungen folgender Art sowie Trennung von mehreren Tags in einem Tag\n",
    "metamarkierungen = [\"act_\", \"activity: \", \"meta_\", \"university: \", \"dm_\", \"type: \", \"t_\", \"obj_\", \"object: \", \"goal_\", \"field: \", \"supervisor: \"]\n",
    "seperatoren = [\" / \", \", \", \" - \", \" & \", \"&\"]\n",
    "\n",
    "with open(\"Zotero.csv\", encoding = \"utf-8\") as datei:\n",
    "    for row in datei:\n",
    "        element = row.strip(\"\\ufeff\").strip().split(\";\")\n",
    "        tag = element[0]\n",
    "        lang = element[1]\n",
    "        if tag == \"Tag\" and lang == \"Sprache\":\n",
    "            continue\n",
    "        for markierung in metamarkierungen:\n",
    "            tag = tag.replace(markierung, \"\")\n",
    "        if re.findall(\"[a-z][A-Z]\", tag) and tag != \"Thesis (PhD level)\":\n",
    "            for match in re.finditer((\"[a-z][A-Z]\"), tag):\n",
    "                start = match.start() #gibt Index des ersten Zeichens von Match aus\n",
    "                end = match.end()\n",
    "                tag = tag[:start+1] + \" \" + tag[end-1:]\n",
    "        #for sep in seperatoren:\n",
    "            #if sep in tag:\n",
    "                #tags = tag.split(sep)\n",
    "            \n",
    "        zotero_orig[tag] = {\"lang\": lang} #in Zukunft noch weitere Informationen hinzufügbar\n",
    "\n",
    "zotero = {key.lower():value for (key,value) in zotero_orig.items()}\n",
    "\n",
    "with open(\"zotero_konde.json\", \"w\", encoding = \"utf-8\") as datei:\n",
    "    json.dump(zotero, datei, ensure_ascii = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10 (tags/v3.9.10:f2f3f53, Jan 17 2022, 15:14:21) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "472e6bacea13396c951b7e0261ffb3356d3421111b0878bad017ca28094a9cfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
